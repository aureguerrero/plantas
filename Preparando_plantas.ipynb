{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preparando plantas.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aureguerrero/plantas/blob/main/Preparando_plantas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio\n",
        "!pip install affine\n",
        "!pip install pyproj\n",
        "!pip install pygeoj\n",
        "!pip install geopandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckHTTTanIeGt",
        "outputId": "1d042449-66a9-4303-8a67-92d41d588e04"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.7/dist-packages (1.2.10)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from rasterio) (21.4.0)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.7/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from rasterio) (2021.10.8)\n",
            "Requirement already satisfied: snuggs>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.4.7)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.21.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rasterio) (57.4.0)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from rasterio) (7.1.2)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.7/dist-packages (from rasterio) (2.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.7/dist-packages (from snuggs>=1.4.1->rasterio) (3.0.7)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.7/dist-packages (2.3.0)\n",
            "Requirement already satisfied: pyproj in /usr/local/lib/python3.7/dist-packages (3.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from pyproj) (2021.10.8)\n",
            "Requirement already satisfied: pygeoj in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.7/dist-packages (0.10.2)\n",
            "Requirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.3.5)\n",
            "Requirement already satisfied: shapely>=1.6 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.8.0)\n",
            "Requirement already satisfied: fiona>=1.8 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.8.21)\n",
            "Requirement already satisfied: pyproj>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (3.2.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (57.4.0)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (7.1.2)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (2.5.0)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.15.0)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (0.7.2)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (21.4.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (2021.10.8)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (1.21.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2018.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdal\n",
        "import rasterio\n",
        "import numpy as np\n",
        "from affine import Affine\n",
        "from pyproj import Proj, transform\n",
        "import pygeoj\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import shutil\n",
        "import random as rd\n",
        "import os\n",
        "ancho= 512"
      ],
      "metadata": {
        "id": "L3GTeodtGrYZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Del Repositor"
      ],
      "metadata": {
        "id": "GuakLv3Ny1BN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/aureguerrero/plantas.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w22m4Lulsmk8",
        "outputId": "8f0d2853-1049-44a6-91ad-5007248fced8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'plantas'...\n",
            "remote: Enumerating objects: 1360, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 1360 (delta 20), reused 0 (delta 0), pack-reused 1322\u001b[K\n",
            "Receiving objects: 100% (1360/1360), 236.34 MiB | 25.09 MiB/s, done.\n",
            "Resolving deltas: 100% (391/391), done.\n",
            "Checking out files: 100% (1061/1061), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd plantas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyX5jLa50seo",
        "outputId": "e88fae1b-92fa-458a-8c53-4b43681c1e72"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/plantas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir conj_ima_new\n",
        "%mkdir archivos_new"
      ],
      "metadata": {
        "id": "zrcfEFPy01de"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pasar de json a csv\n",
        "Subir los archivos .tif y .geojson a la carpeta plantas/archivos_new/\n",
        "\n",
        "***Importante!!!!*** *el comienzo del nombre del archivo .geojson debe comenzar con el nombre completo del .tif correspondiente*."
      ],
      "metadata": {
        "id": "0SkqSz7Uy-i6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "archivos=[_ for _ in os.listdir('/content/plantas/archivos_new') if _.endswith('.tif')]\n",
        "\n",
        "\n",
        "for nombre in archivos:\n",
        "  nombre=nombre[:-4]\n",
        "  json=[_ for _ in os.listdir('/content/plantas/archivos_new/') if _.endswith('.geojson') and _.startswith(nombre)]\n",
        "  df = gpd.read_file('/content/plantas/archivos_new/'+json[0])\n",
        "  fname = '/content/plantas/archivos_new/'+nombre+'.tif'\n",
        "\n",
        "  # Read raster\n",
        "  with rasterio.open(fname) as r:\n",
        "      T0 = r.transform  # upper-left pixel corner affine transform\n",
        "      p1 = Proj(r.crs)\n",
        "      A = r.read()\n",
        "  plantas={'id':[],'coord':[],'minx':[],'maxx':[],'miny':[],'maxy':[]}\n",
        "  for i in range(0,len(df)):\n",
        "    a=df['geometry'][i]\n",
        "    points = []\n",
        "    for polygon in a:\n",
        "      points.extend(polygon.exterior.coords[:-1])\n",
        "    points =np.array([point for polygon in a for point in polygon.exterior.coords[:-1]])\n",
        "    points[:,0]=np.int16((points[:,0]-T0[2])/T0[0])\n",
        "    points[:,1]=np.int16((points[:,1]-T0[5])/T0[4])\n",
        "    minx, maxx, miny, maxy=np.int16(np.min(points[:,0])), np.int16(np.max(points[:,0])),np.int16(np.min(points[:,1])), np.int16(np.max(points[:,1]))\n",
        "    #plantas.append({'coord':points,'extrem':[[minx,maxx],[miny,maxy]]})\n",
        "    plantas['id'].append(i), plantas['coord'].append(points), plantas['minx'].append(minx),plantas['maxx'].append(maxx),plantas['miny'].append(miny),plantas['maxy'].append(maxy)\n",
        "  image=gdal.Open(fname).ReadAsArray().transpose([1,2,0])\n",
        "  print(np.shape(image))\n",
        "  \n",
        "  n=[np.shape(image)[0]//ancho,np.shape(image)[1]//ancho]\n",
        "  for i in range(0,n[0]):\n",
        "    for j in range(0,n[1]):\n",
        "      recorte=image[i*ancho:(i+1)*ancho,j*ancho:(j+1)*ancho,:]\n",
        "      cv2.imwrite(\"/content/plantas/conj_ima_new/\"+nombre+\"_\"+str(i)+\"_\"+str(j)+\".png\",recorte)\n",
        "      pos=np.intersect1d(np.intersect1d(np.intersect1d(np.where(np.array(plantas['miny']) >i*ancho), np.where(np.array(plantas['maxy']) <(i+1)*ancho)),np.where(np.array(plantas['minx']) >j*ancho)),np.where(np.array(plantas['maxx']) <(j+1)*ancho))\n",
        "      np.save(\"/content/plantas/conj_ima_new/\"+nombre+\"_\"+str(i)+\"_\"+str(j)+\".npy\",[plantas['coord'][t]-[j*ancho,i*ancho] for t in pos])\n",
        "    recorte=image[i*ancho:(i+1)*ancho,np.shape(image)[1]-ancho:np.shape(image)[1],:]\n",
        "    cv2.imwrite(\"/content/plantas/conj_ima_new/\"+nombre+\"_\"+str(i)+\"_\"+str(n[1])+\".png\",recorte)\n",
        "    pos=np.intersect1d(np.intersect1d(np.intersect1d(np.where(np.array(plantas['miny']) >i*ancho), np.where(np.array(plantas['maxy']) <(i+1)*ancho)),np.where(np.array(plantas['minx']) >np.shape(image)[1]-ancho)),np.where(np.array(plantas['maxx']) <np.shape(image)[1]))\n",
        "    np.save(\"/content/plantas/conj_ima_new/\"+nombre+\"_\"+str(i)+\"_\"+str(n[1])+\".npy\",[plantas['coord'][t]-[np.shape(image)[1]-ancho,i*ancho] for t in pos])\n",
        "\n",
        "  for j in range(0,n[1]):\n",
        "    recorte=image[np.shape(image)[0]-ancho:np.shape(image)[0],j*ancho:(j+1)*ancho,:]\n",
        "    cv2.imwrite(\"/content/plantas/conj_ima_new/\"+nombre+\"_\"+str(n[0])+\"_\"+str(j)+\".png\",recorte)\n",
        "    pos=np.intersect1d(np.intersect1d(np.intersect1d(np.where(np.array(plantas['miny']) >np.shape(image)[0]-ancho), np.where(np.array(plantas['maxy']) <np.shape(image)[0])),np.where(np.array(plantas['minx']) >j*ancho)),np.where(np.array(plantas['maxx']) <(j+1)*ancho))\n",
        "    np.save(\"/content/plantas/conj_ima_new/\"+nombre+\"_\"+str(n[0])+\"_\"+str(j)+\".npy\",[plantas['coord'][t]-[j*ancho,np.shape(image)[0]-ancho] for t in pos])\n",
        "\n",
        "  recorte=image[np.shape(image)[0]-ancho:np.shape(image)[0],np.shape(image)[1]-ancho:np.shape(image)[1],:]\n",
        "  cv2.imwrite(\"/content/plantas/conj_ima_new/\"+nombre+\"_\"+str(n[0])+\"_\"+str(n[1])+\".png\",recorte)\n",
        "  pos=np.intersect1d(np.intersect1d(np.intersect1d(np.where(np.array(plantas['miny']) >np.shape(image)[0]-ancho), np.where(np.array(plantas['maxy']) <np.shape(image)[0])),np.where(np.array(plantas['minx']) >np.shape(image)[1]-ancho)),np.where(np.array(plantas['maxx']) <np.shape(image)[1]))\n",
        "  np.save(\"/content/plantas/conj_ima_new/\"+nombre+\"_\"+str(n[0])+\"_\"+str(n[1])+\".npy\",[plantas['coord'][t]-[np.shape(image)[1]-ancho,np.shape(image)[0]-ancho] for t in pos])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d9120c0-dacf-4d5a-bab1-b9d74efa8a70",
        "id": "HOMHYLyWy-i7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(843, 2000, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr = np.asanyarray(arr)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.ma.core import sort\n",
        "pos=[_ for _ in sort(os.listdir('/content/plantas/conj_ima_new')) if _.endswith('npy')]\n",
        "rd.shuffle(pos)\n",
        "split = int(0.8 *len(pos))\n",
        "train=pos[-split:]\n",
        "test=pos[:-split]\n"
      ],
      "metadata": {
        "id": "5LcwsHmUJyRw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir conj_ima_new/val\n",
        "%mkdir conj_ima_new/train"
      ],
      "metadata": {
        "id": "h8UoICDtxUhk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in train:\n",
        "  shutil.copy(\"/content/plantas/conj_ima_new/\"+i[:-3]+'png',\"/content/plantas/conj_ima_new/train/\"+i[:-3]+'png')\n",
        "  shutil.copy(\"/content/plantas/conj_ima_new/\"+i,\"/content/plantas/conj_ima_new/train/\"+i)\n",
        "for i in test:\n",
        "  shutil.copy(\"/content/plantas/conj_ima_new/\"+i[:-3]+'png',\"/content/plantas/conj_ima_new/val/\"+i[:-3]+'png')\n",
        "  shutil.copy(\"/content/plantas/conj_ima_new/\"+i,\"/content/plantas/conj_ima_new/val/\"+i)\n"
      ],
      "metadata": {
        "id": "djZ8iAW9RIwZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_train_png=[_ for _ in os.listdir('/content/plantas/conj_ima_new/train/') if _.endswith('.png')]\n",
        "np.save('/content/plantas/conj_ima_new/train/list_train_png.npy',list_train_png)\n",
        "list_train_npy=[_ for _ in os.listdir('/content/plantas/conj_ima_new/train/') if _.endswith('.npy' and _.startswith('dji'))]\n",
        "np.save('/content/plantas/conj_ima_new/train/list_train_npy.npy',list_train_npy)\n",
        "list_test_png=[_ for _ in os.listdir('/content/plantas/conj_ima_new/val/') if _.endswith('.png')]\n",
        "np.save('/content/plantas/conj_ima_new/val/list_test_png.npy',list_train_png)\n",
        "list_test_npy=[_ for _ in os.listdir('/content/plantas/conj_ima_new/val/') if _.endswith('.npy') and _.startswith('dji')]\n",
        "np.save('/content/plantas/conj_ima_new/val/list_test_npy.npy',list_train_npy)\n"
      ],
      "metadata": {
        "id": "Qzv9-rtaUdhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_train_png=[_ for _ in os.listdir('/content/plantas/train/') if _.endswith('.png') and _.startswith('dji')]\n",
        "np.save('/content/plantas/train/list_train_png.npy',list_train_png)\n",
        "np.save('/content/plantas/list_train_png.npy',list_train_png)\n",
        "list_train_npy=[_ for _ in os.listdir('/content/plantas/train/') if _.endswith('.npy') and _.startswith('dji')]\n",
        "np.save('/content/plantas/train/list_train_npy.npy',list_train_npy)\n",
        "np.save('/content/plantas/list_train_npy.npy',list_train_npy)\n",
        "list_test_png=[_ for _ in os.listdir('/content/plantas/val/') if _.endswith('.png') and _.startswith('dji')]\n",
        "np.save('/content/plantas/val/list_test_png.npy',list_test_png)\n",
        "np.save('/content/plantas/list_test_png.npy',list_test_png)\n",
        "list_test_npy=[_ for _ in os.listdir('/content/plantas/val/') if _.endswith('.npy') and _.startswith('dji')]\n",
        "np.save('/content/plantas/val/list_test_npy.npy',list_test_npy)\n",
        "np.save('/content/plantas/list_test_npy.npy',list_test_npy)"
      ],
      "metadata": {
        "id": "J08Reebx-8Po"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_test_npy=np.load('list_test_npy.npy')\n",
        "list_train_npy=np.load('list_train_npy.npy')"
      ],
      "metadata": {
        "id": "KAF1OpQfyQlp"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "at=[['filename', 'file_size', 'file_attributes', 'region_count', 'region_id', 'region_shape_attributes', 'region_attributes']]\n",
        "at_new=[['filename', 'file_size', 'file_attributes', 'region_count', 'region_id', 'region_shape_attributes', 'region_attributes']]\n",
        "for i in list_test_npy:\n",
        "  a=np.load(\"/content/plantas/val/\"+i, allow_pickle=True)\n",
        "  filename=i[:-3]+'png'\n",
        "  file_size=str(os.path.getsize(r'/content/plantas/val/'+i[:-3]+'png'))\n",
        "  file_attributes='\"{}\"'\n",
        "  region_count=str(len(a))\n",
        "  for j in range(0,len(a)):\n",
        "    region_id=str(j)\n",
        "    region_shape_attributes='\"{\"\"name\"\":\"\"polygon\"\",\"\"all_points_x\"\":['+','.join(str(np.int16(x)) for x in a[j][:,0])+'],\"\"all_points_y\"\":['+','.join(str(np.int16(x)) for x in a[j][:,1])+']}\"'\n",
        "    region_attributes='\"\"obj\"\":\"\"planta\"\"'\n",
        "    at.append([filename, file_size, file_attributes, region_count, region_id, region_shape_attributes, region_attributes])\n",
        "for i in test:\n",
        "  a=np.load(\"/content/plantas/conj_ima_new/val/\"+i, allow_pickle=True)\n",
        "  filename=i[:-3]+'png'\n",
        "  file_size=str(os.path.getsize(r'/content/plantas/conj_ima_new/val/'+i[:-3]+'png'))\n",
        "  file_attributes='\"{}\"'\n",
        "  region_count=str(len(a))\n",
        "  for j in range(0,len(a)):\n",
        "    region_id=str(j)\n",
        "    region_shape_attributes='\"{\"\"name\"\":\"\"polygon\"\",\"\"all_points_x\"\":['+','.join(str(np.int16(x)) for x in a[j][:,0])+'],\"\"all_points_y\"\":['+','.join(str(np.int16(x)) for x in a[j][:,1])+']}\"'\n",
        "    region_attributes='\"\"obj\"\":\"\"planta\"\"'\n",
        "    at.append([filename, file_size, file_attributes, region_count, region_id, region_shape_attributes, region_attributes])\n",
        "    at_new.append([filename, file_size, file_attributes, region_count, region_id, region_shape_attributes, region_attributes])\n",
        "\n",
        "\n",
        "\n",
        "np.savetxt(\"/content/plantas/conj_ima_new/val/numpy_test.csv\", at, delimiter =\",\",fmt ='% s')\n",
        "np.savetxt(\"/content/plantas/conj_ima_new/val/numpy_test_new.csv\", at_new, delimiter =\",\",fmt ='% s')"
      ],
      "metadata": {
        "id": "p6Mfu7Qdy-jC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "at=[['filename', 'file_size', 'file_attributes', 'region_count', 'region_id', 'region_shape_attributes', 'region_attributes']]\n",
        "at_new=[['filename', 'file_size', 'file_attributes', 'region_count', 'region_id', 'region_shape_attributes', 'region_attributes']]\n",
        "for i in list_train_npy:\n",
        "  a=np.load(\"/content/plantas/train/\"+i, allow_pickle=True)\n",
        "  filename=i[:-3]+'png'\n",
        "  file_size=str(os.path.getsize(r'/content/plantas/train/'+i[:-3]+'png'))\n",
        "  file_attributes='\"{}\"'\n",
        "  region_count=str(len(a))\n",
        "  for j in range(0,len(a)):\n",
        "    region_id=str(j)\n",
        "    region_shape_attributes='\"{\"\"name\"\":\"\"polygon\"\",\"\"all_points_x\"\":['+','.join(str(np.int16(x)) for x in a[j][:,0])+'],\"\"all_points_y\"\":['+','.join(str(np.int16(x)) for x in a[j][:,1])+']}\"'\n",
        "    region_attributes='\"\"obj\"\":\"\"planta\"\"'\n",
        "    at.append([filename, file_size, file_attributes, region_count, region_id, region_shape_attributes, region_attributes])\n",
        "\n",
        "for i in train:\n",
        "  a=np.load(\"/content/plantas/conj_ima_new/train/\"+i, allow_pickle=True)\n",
        "  filename=i[:-3]+'png'\n",
        "  file_size=str(os.path.getsize(r'/content/plantas/conj_ima_new/train/'+i[:-3]+'png'))\n",
        "  file_attributes='\"{}\"'\n",
        "  region_count=str(len(a))\n",
        "  for j in range(0,len(a)):\n",
        "    region_id=str(j)\n",
        "    region_shape_attributes='\"{\"\"name\"\":\"\"polygon\"\",\"\"all_points_x\"\":['+','.join(str(np.int16(x)) for x in a[j][:,0])+'],\"\"all_points_y\"\":['+','.join(str(np.int16(x)) for x in a[j][:,1])+']}\"'\n",
        "    region_attributes='\"\"obj\"\":\"\"planta\"\"'\n",
        "    at.append([filename, file_size, file_attributes, region_count, region_id, region_shape_attributes, region_attributes])\n",
        "    at_new.append([filename, file_size, file_attributes, region_count, region_id, region_shape_attributes, region_attributes])\n",
        "\n",
        "\n",
        "\n",
        "np.savetxt(\"/content/plantas/conj_ima_new/train/numpy_train.csv\", at, delimiter =\",\",fmt ='% s')\n",
        "np.savetxt(\"/content/plantas/conj_ima_new/train/numpy_train_new.csv\", at_new, delimiter =\",\",fmt ='% s')"
      ],
      "metadata": {
        "id": "ENS4HWbgy-jD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pasar de json a txt"
      ],
      "metadata": {
        "id": "T-T8OiVP5rbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir /content/plantas/conj_ima_new/val/labels\n",
        "%mkdir /content/plantas/conj_ima_new/train/labels"
      ],
      "metadata": {
        "id": "kTO03joN6Hmq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "fileDir = \"/content/plantas/conj_ima_new/\"\n",
        "list_train_npy=[_ for _ in os.listdir(fileDir+'train/') if _.endswith(r\".npy\")]\n",
        "\n",
        "for i in train:\n",
        "  a=np.load(fileDir+'train/'+i,allow_pickle=True)\n",
        "  np.savetxt(fileDir+'train/labels/'+i[:-4]+'.txt',[str(0)+ ' '+str(\"{0:.6f}\".format(np.mean(a[j][0,:]/511)))+' '+str(\"{0:.6f}\".format(np.mean(a[j][1,:]/511)))+' '+str(\"{0:.6f}\".format((np.max(a[j][0,:])-np.min(a[j][0,:]))/511.))+' '+str(\"{0:.6f}\".format((np.max(a[j][1,:])-np.min(a[j][1,:]))/511.)) for j in range(0,len(a))],delimiter =\",\",fmt='%s')\n",
        "\n",
        "list_test_npy=[_ for _ in os.listdir(fileDir+'val/') if _.endswith(r\".npy\")]\n",
        "\n",
        "for i in test:\n",
        "  a=np.load(fileDir+'val/'+i,allow_pickle=True)\n",
        "  np.savetxt(fileDir+'val/labels/'+i[:-4]+'.txt',[str(0)+ ' '+str(\"{0:.6f}\".format(np.mean(a[j][0,:]/511)))+' '+str(\"{0:.6f}\".format(np.mean(a[j][1,:]/511)))+' '+str(\"{0:.6f}\".format((np.max(a[j][0,:])-np.min(a[j][0,:]))/511.))+' '+str(\"{0:.6f}\".format((np.max(a[j][1,:])-np.min(a[j][1,:]))/511.)) for j in range(0,len(a))],delimiter =\",\",fmt='%s')"
      ],
      "metadata": {
        "id": "LIK9hGzD5rbx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pasar a xml"
      ],
      "metadata": {
        "id": "VEBaE1XZ7emT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir /content/plantas/conj_ima_new/val/xml\n",
        "%mkdir /content/plantas/conj_ima_new/train/xml"
      ],
      "metadata": {
        "id": "wwIxLj6x7gnW"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "from PIL import Image\n",
        "\n",
        "folder_holding_files = '/content/plantas/conj_ima_new/val/'\n",
        "\n",
        "\n",
        "\n",
        "for image_name in [_ for _ in os.listdir(folder_holding_files) if _.endswith('.png')]:\n",
        "  orig_img = Image.open(folder_holding_files+image_name) # open the image\n",
        "  image_width = orig_img.width\n",
        "  image_height = orig_img.height\n",
        "  # Start the XML file\n",
        "  with open(folder_holding_files+'xml/'+image_name[:-3]+'xml', 'w') as f:\n",
        "    f.write('<annotation>\\n')\n",
        "    f.write('\\t<folder>XML</folder>\\n')\n",
        "    f.write('\\t<filename>' + image_name + '</filename>\\n')\n",
        "    f.write('\\t<path>' + folder_holding_files + image_name + '</path>\\n')\n",
        "    f.write('\\t<source>\\n')\n",
        "    f.write('\\t\\t<database>Unknown</database>\\n')\n",
        "    f.write('\\t</source>\\n')\n",
        "    f.write('\\t<size>\\n')\n",
        "    f.write('\\t\\t<width>' + str(image_width) + '</width>\\n')\n",
        "    f.write('\\t\\t<height>' + str(image_height) + '</height>\\n')\n",
        "    f.write('\\t\\t<depth>3</depth>\\n') # assuming a 3 channel color image (RGB)\n",
        "    f.write('\\t</size>\\n')\n",
        "    f.write('\\t<segmented>0</segmented>\\n')\n",
        "    a=np.load(folder_holding_files+image_name[:-3]+'npy',allow_pickle=True)\n",
        "    for j in range(0,len(a)):\n",
        "      # write each object to the file\n",
        "      f.write('\\t<object>\\n')\n",
        "      f.write('\\t\\t<name>' + 'planta' + '</name>\\n')\n",
        "      f.write('\\t\\t<pose>Unspecified</pose>\\n')\n",
        "      f.write('\\t\\t<truncated>0</truncated>\\n')\n",
        "      f.write('\\t\\t<difficult>0</difficult>\\n')\n",
        "      f.write('\\t\\t<bndbox>\\n')\n",
        "      f.write('\\t\\t\\t<xmin>' + str(np.int64(np.min(a[j],0)[0])) + '</xmin>\\n')\n",
        "      f.write('\\t\\t\\t<ymin>' + str(np.int64(np.min(a[j],0)[1])) + '</ymin>\\n')\n",
        "      f.write('\\t\\t\\t<xmax>' + str(np.int64(np.max(a[j],0)[0])) + '</xmax>\\n')\n",
        "      f.write('\\t\\t\\t<ymax>' + str(np.int64(np.max(a[j],0)[1])) + '</ymax>\\n')\n",
        "      f.write('\\t\\t</bndbox>\\n')\n",
        "      f.write('\\t</object>\\n')\n",
        "\n",
        "        # Close the annotation tag once all the objects have been written to the file\n",
        "    f.write('</annotation>\\n')\n",
        "    f.close() # Close the file\n",
        "\n",
        "\n",
        "folder_holding_files = '/content/plantas/conj_ima_new/train/'\n",
        "\n",
        "\n",
        "\n",
        "for image_name in [_ for _ in os.listdir(folder_holding_files) if _.endswith('.png')]:\n",
        "  orig_img = Image.open(folder_holding_files+image_name) # open the image\n",
        "  image_width = orig_img.width\n",
        "  image_height = orig_img.height\n",
        "  # Start the XML file\n",
        "  with open(folder_holding_files+'xml/'+image_name[:-3]+'xml', 'w') as f:\n",
        "    f.write('<annotation>\\n')\n",
        "    f.write('\\t<folder>XML</folder>\\n')\n",
        "    f.write('\\t<filename>' + image_name + '</filename>\\n')\n",
        "    f.write('\\t<path>' + folder_holding_files + image_name + '</path>\\n')\n",
        "    f.write('\\t<source>\\n')\n",
        "    f.write('\\t\\t<database>Unknown</database>\\n')\n",
        "    f.write('\\t</source>\\n')\n",
        "    f.write('\\t<size>\\n')\n",
        "    f.write('\\t\\t<width>' + str(image_width) + '</width>\\n')\n",
        "    f.write('\\t\\t<height>' + str(image_height) + '</height>\\n')\n",
        "    f.write('\\t\\t<depth>3</depth>\\n') # assuming a 3 channel color image (RGB)\n",
        "    f.write('\\t</size>\\n')\n",
        "    f.write('\\t<segmented>0</segmented>\\n')\n",
        "    a=np.load(folder_holding_files+image_name[:-3]+'npy',allow_pickle=True)\n",
        "    for j in range(0,len(a)):\n",
        "      # write each object to the file\n",
        "      f.write('\\t<object>\\n')\n",
        "      f.write('\\t\\t<name>' + 'planta' + '</name>\\n')\n",
        "      f.write('\\t\\t<pose>Unspecified</pose>\\n')\n",
        "      f.write('\\t\\t<truncated>0</truncated>\\n')\n",
        "      f.write('\\t\\t<difficult>0</difficult>\\n')\n",
        "      f.write('\\t\\t<bndbox>\\n')\n",
        "      f.write('\\t\\t\\t<xmin>' + str(np.int64(np.min(a[j],0)[0])) + '</xmin>\\n')\n",
        "      f.write('\\t\\t\\t<ymin>' + str(np.int64(np.min(a[j],0)[1])) + '</ymin>\\n')\n",
        "      f.write('\\t\\t\\t<xmax>' + str(np.int64(np.max(a[j],0)[0])) + '</xmax>\\n')\n",
        "      f.write('\\t\\t\\t<ymax>' + str(np.int64(np.max(a[j],0)[1])) + '</ymax>\\n')\n",
        "      f.write('\\t\\t</bndbox>\\n')\n",
        "      f.write('\\t</object>\\n')\n",
        "\n",
        "        # Close the annotation tag once all the objects have been written to the file\n",
        "    f.write('</annotation>\\n')\n",
        "    f.close() # Close the file\n"
      ],
      "metadata": {
        "id": "4vaP031K7emm"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r conj_ima_new.zip /content/plantas/conj_ima_new/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nDAzCWp_FP7",
        "outputId": "5f684bfe-2aba-452c-bf81-63de5aede66a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/plantas/conj_ima_new/ (stored 0%)\n",
            "  adding: content/plantas/conj_ima_new/dji-0044crop_maiz_1_1.npy (deflated 85%)\n",
            "  adding: content/plantas/conj_ima_new/dji-0044crop_maiz_0_2.png (deflated 1%)\n",
            "  adding: content/plantas/conj_ima_new/dji-0044crop_maiz_1_2.png (deflated 1%)\n",
            "  adding: content/plantas/conj_ima_new/dji-0044crop_maiz_0_2.npy (deflated 85%)\n",
            "  adding: content/plantas/conj_ima_new/dji-0044crop_maiz_1_3.npy (deflated 86%)\n",
            "  adding: content/plantas/conj_ima_new/dji-0044crop_maiz_0_1.npy (deflated 85%)\n",
            "  adding: content/plantas/conj_ima_new/dji-0044crop_maiz_1_0.npy (deflated 85%)\n",
            "  adding: content/plantas/conj_ima_new/dji-0044crop_maiz_0_0.npy (deflated 85%)\n",
            "  adding: content/plantas/conj_ima_new/dji-0044crop_maiz_1_0.png (deflated 2%)\n",
            "  adding: content/plantas/conj_ima_new/dji-0044crop_maiz_0_3.png (deflated 1%)\n",
            "  adding: content/plantas/conj_ima_new/train/ (stored 0%)\n",
            "  adding: content/plantas/conj_ima_new/train/dji-0044crop_maiz_1_1.npy (deflated 85%)\n",
            "  adding: content/plantas/conj_ima_new/train/labels/ (stored 0%)\n",
            "  adding: content/plantas/conj_ima_new/train/labels/dji-0044crop_maiz_1_0.txt (deflated 58%)\n",
            "  adding: content/plantas/conj_ima_new/train/labels/dji-0044crop_maiz_0_2.txt (deflated 56%)\n",
            "  adding: content/plantas/conj_ima_new/train/labels/dji-0044crop_maiz_1_2.txt (deflated 57%)\n",
            "  adding: content/plantas/conj_ima_new/train/labels/dji-0044crop_maiz_0_0.txt (deflated 58%)\n",
            "  adding: content/plantas/conj_ima_new/train/labels/dji-0044crop_maiz_0_3.txt (deflated 57%)\n",
            "  adding: content/plantas/conj_ima_new/train/labels/dji-0044crop_maiz_1_1.txt (deflated 58%)\n",
            "  adding: content/plantas/conj_ima_new/train/numpy_train_new.csv (deflated 86%)\n",
            "  adding: content/plantas/conj_ima_new/train/dji-0044crop_maiz_0_2.png (deflated 1%)\n",
            "  adding: content/plantas/conj_ima_new/train/dji-0044crop_maiz_1_2.png (deflated 1%)\n",
            "  adding: content/plantas/conj_ima_new/train/dji-0044crop_maiz_0_2.npy (deflated 85%)\n",
            "  adding: content/plantas/conj_ima_new/train/dji-0044crop_maiz_1_0.npy (deflated 85%)\n",
            "  adding: content/plantas/conj_ima_new/train/dji-0044crop_maiz_0_0.npy (deflated 85%)\n",
            "  adding: content/plantas/conj_ima_new/train/dji-0044crop_maiz_1_0.png (deflated 2%)\n",
            "  adding: content/plantas/conj_ima_new/train/dji-0044crop_maiz_0_3.png (deflated 1%)\n",
            "  adding: content/plantas/conj_ima_new/train/numpy_train.csv (deflated 85%)\n",
            "  adding: content/plantas/conj_ima_new/train/list_train_png.npy (deflated 80%)\n",
            "  adding: content/plantas/conj_ima_new/train/dji-0044crop_maiz_0_3.npy (deflated 85%)\n",
            "  adding: content/plantas/conj_ima_new/train/dji-0044crop_maiz_1_2.npy (deflated 85%)\n",
            "  adding: content/plantas/conj_ima_new/train/dji-0044crop_maiz_0_0.png (deflated 2%)\n",
            "  adding: content/plantas/conj_ima_new/train/dji-0044crop_maiz_1_1.png (deflated 1%)\n",
            "  adding: content/plantas/conj_ima_new/train/list_train_npy.npy (deflated 81%)\n",
            "  adding: content/plantas/conj_ima_new/train/xml/ (stored 0%)\n",
            "  adding: content/plantas/conj_ima_new/train/xml/dji-0044crop_maiz_1_0.xml (deflated 86%)\n",
            "  adding: content/plantas/conj_ima_new/train/xml/dji-0044crop_maiz_0_0.xml (deflated 85%)\n",
            "  adding: content/plantas/conj_ima_new/train/xml/dji-0044crop_maiz_0_2.xml (deflated 84%)\n",
            "  adding: content/plantas/conj_ima_new/train/xml/dji-0044crop_maiz_0_3.xml (deflated 84%)\n",
            "  adding: content/plantas/conj_ima_new/train/xml/dji-0044crop_maiz_1_1.xml (deflated 86%)\n",
            "  adding: content/plantas/conj_ima_new/train/xml/dji-0044crop_maiz_1_2.xml (deflated 83%)\n",
            "  adding: content/plantas/conj_ima_new/val/ (stored 0%)\n",
            "  adding: content/plantas/conj_ima_new/val/list_test_png.npy (deflated 61%)\n",
            "  adding: content/plantas/conj_ima_new/val/labels/ (stored 0%)\n",
            "  adding: content/plantas/conj_ima_new/val/labels/dji-0044crop_maiz_1_3.txt (deflated 59%)\n",
            "  adding: content/plantas/conj_ima_new/val/labels/dji-0044crop_maiz_0_1.txt (deflated 57%)\n",
            "  adding: content/plantas/conj_ima_new/val/list_test_npy.npy (deflated 61%)\n",
            "  adding: content/plantas/conj_ima_new/val/numpy_test_new.csv (deflated 84%)\n",
            "  adding: content/plantas/conj_ima_new/val/dji-0044crop_maiz_1_3.npy (deflated 86%)\n",
            "  adding: content/plantas/conj_ima_new/val/dji-0044crop_maiz_0_1.npy (deflated 85%)\n",
            "  adding: content/plantas/conj_ima_new/val/dji-0044crop_maiz_0_1.png (deflated 1%)\n",
            "  adding: content/plantas/conj_ima_new/val/numpy_test.csv (deflated 85%)\n",
            "  adding: content/plantas/conj_ima_new/val/xml/ (stored 0%)\n",
            "  adding: content/plantas/conj_ima_new/val/xml/dji-0044crop_maiz_0_1.xml (deflated 86%)\n",
            "  adding: content/plantas/conj_ima_new/val/xml/dji-0044crop_maiz_1_3.xml (deflated 86%)\n",
            "  adding: content/plantas/conj_ima_new/val/dji-0044crop_maiz_1_3.png (deflated 1%)\n",
            "  adding: content/plantas/conj_ima_new/dji-0044crop_maiz_0_1.png (deflated 1%)\n",
            "  adding: content/plantas/conj_ima_new/dji-0044crop_maiz_0_3.npy (deflated 85%)\n",
            "  adding: content/plantas/conj_ima_new/dji-0044crop_maiz_1_2.npy (deflated 85%)\n",
            "  adding: content/plantas/conj_ima_new/dji-0044crop_maiz_0_0.png (deflated 2%)\n",
            "  adding: content/plantas/conj_ima_new/dji-0044crop_maiz_1_1.png (deflated 1%)\n",
            "  adding: content/plantas/conj_ima_new/dji-0044crop_maiz_1_3.png (deflated 1%)\n"
          ]
        }
      ]
    }
  ]
}